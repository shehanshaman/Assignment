{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f= open(\"trainset.txt\",\"r\")\n",
    "# #print(f.read())\n",
    "# x = []\n",
    "# for line in f:\n",
    "#         fields = line.split(\"\\t\")\n",
    "#         #print(fields[0])\n",
    "#         x.append(fields[0]) \n",
    "        \n",
    "# print(x);\n",
    "\n",
    "import re #regex\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def preprocess(eliment):\n",
    "      \n",
    "    eliment = re.sub(r'([^\\s\\w]|_)+', '', eliment) # Remove all the special characters except space\n",
    "    eliment = eliment.lower()\n",
    "    eliment = re.sub(r'\\s+', ' ', eliment, flags=re.I)# Substituting multiple spaces with single space\n",
    "\n",
    "    all_words = eliment.split()\n",
    "    en_stops = set(stopwords.words('english')) #stopword handle\n",
    "    eliment = \"\"\n",
    "    ps = PorterStemmer() #stemming handle  \n",
    "\n",
    "    for word in all_words: \n",
    "        if word not in en_stops:   \n",
    "            eliment +=  ps.stem(word) +\" \"\n",
    "\n",
    "    return eliment \n",
    "\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('trainset.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\"\\t\") for line in stripped if line)\n",
    "    lin = preprocess(lines)\n",
    "    with open('log.csv', 'w') as out_file:\n",
    "        \n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('class', 'title','date','body'))\n",
    "        writer.writerows(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'log.csv'\n",
    "data = pd.read_csv(fileName)\n",
    "Y = data['class']\n",
    "data.drop(['class'], axis=1, inplace=True)\n",
    "X = data\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#x = preprocess(x)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X)\n",
    "X_train_counts.shape\n",
    "#print(X_train_counts)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#Counter(X['title']).most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
